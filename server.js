const express = require('express');
const cors    = require('cors');
const path    = require('path');
const multer  = require('multer');
const fs      = require('fs');

const app  = express();
const PORT = 3002;

// â”€â”€ Ollama ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const OLLAMA_URL = 'http://localhost:11434';
const MODEL_NAME = 'bitdot-ai';

// â”€â”€ íŒŒì¼ ì—…ë¡œë“œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const upload = multer({
  dest: 'uploads/',
  limits: { fileSize: 10 * 1024 * 1024 },
  fileFilter: (req, file, cb) => {
    const allowedExt = ['.txt','.js','.ts','.jsx','.tsx','.py','.java',
                        '.html','.css','.json','.md','.csv','.xml','.go',
                        '.rs','.c','.cpp','.h','.php','.rb','.sh','.yaml','.yml'];
    const ext = path.extname(file.originalname).toLowerCase();
    if (allowedExt.includes(ext)) cb(null, true);
    else cb(new Error('ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹'));
  }
});

app.use(cors());
app.use(express.json({ limit: '5mb' }));

if (!fs.existsSync('uploads')) fs.mkdirSync('uploads');

// â”€â”€ í•œêµ­ì–´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const SYSTEM_PROMPT = `ë‹¹ì‹ ì€ í•œêµ­ì–´ AI ì–´ì‹œìŠ¤í„´íŠ¸ "Bitdot AI"ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ì˜ì–´ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
ì½”ë“œ ë¶„ì„, ë¬¸ì„œ ìš”ì•½, ì§ˆë¬¸ ë‹µë³€ ë“± ëª¨ë“  ì‘ì—…ì„ í•œêµ­ì–´ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
ì½”ë“œ ë¸”ë¡ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹(\`\`\`ì–¸ì–´ëª…)ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.`;

// â”€â”€ ê³µí†µ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function streamOllama(messages, res) {
  const fullMessages = [{ role: 'system', content: SYSTEM_PROMPT }, ...messages];

  const response = await fetch(`${OLLAMA_URL}/api/chat`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: MODEL_NAME,
      messages: fullMessages,
      stream: true,
      options: { temperature: 0.7, num_ctx: 4096 }
    })
  });

  if (!response.ok) throw new Error(`Ollama ì˜¤ë¥˜: ${await response.text()}`);

  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');

  const reader  = response.body.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    const lines = decoder.decode(value, { stream: true }).split('\n').filter(l => l.trim());
    for (const line of lines) {
      try {
        const data = JSON.parse(line);
        if (data.message?.content) res.write(`data: ${JSON.stringify({ content: data.message.content })}\n\n`);
        if (data.done) { res.write(`data: ${JSON.stringify({ done: true })}\n\n`); res.end(); return; }
      } catch {}
    }
  }
  res.end();
}

// â”€â”€ ì¼ë°˜ ì±„íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.post('/api/chat', async (req, res) => {
  const { messages } = req.body;
  if (!messages?.length) return res.status(400).json({ error: 'ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.' });
  try { await streamOllama(messages, res); }
  catch (err) { if (!res.headersSent) res.status(500).json({ error: err.message }); }
});

// â”€â”€ íŒŒì¼ AI ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.post('/api/analyze', upload.single('file'), async (req, res) => {
  if (!req.file) return res.status(400).json({ error: 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.' });

  const { analysisType = 'general', extraPrompt = '' } = req.body;
  const fileName = req.file.originalname;
  const ext      = path.extname(fileName).toLowerCase().slice(1);

  try {
    const fileContent = fs.readFileSync(req.file.path, 'utf-8');
    const maxLen = 6000;
    const content = fileContent.length > maxLen
      ? fileContent.slice(0, maxLen) + '\n\n...(ì´í•˜ ìƒëµ)'
      : fileContent;

    const prompts = {
      general:  `íŒŒì¼ "${fileName}"ì„ ë¶„ì„í•˜ê³  í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n\n\`\`\`${ext}\n${content}\n\`\`\``,
      code:     `ì½”ë“œ "${fileName}"ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ê¸°ëŠ¥ ì„¤ëª…, ë¬¸ì œì , ê°œì„ ë°©ì•ˆì„ í•œêµ­ì–´ë¡œ ì•Œë ¤ì£¼ì„¸ìš”:\n\n\`\`\`${ext}\n${content}\n\`\`\``,
      security: `ì½”ë“œ "${fileName}"ì˜ ë³´ì•ˆ ì·¨ì•½ì ì„ í•œêµ­ì–´ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. ìœ„í—˜ë„ì™€ í•´ê²°ë°©ë²•ë„ ì œì‹œí•´ì£¼ì„¸ìš”:\n\n\`\`\`${ext}\n${content}\n\`\`\``,
      summary:  `íŒŒì¼ "${fileName}"ì˜ í•µì‹¬ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n${content}`,
      review:   `ì½”ë“œ "${fileName}"ì„ ì½”ë“œ ë¦¬ë·°í•´ì£¼ì„¸ìš”. ê°€ë…ì„±, ì„±ëŠ¥, ìœ ì§€ë³´ìˆ˜ì„± ê´€ì ì—ì„œ í•œêµ­ì–´ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:\n\n\`\`\`${ext}\n${content}\n\`\`\``,
    };

    let prompt = prompts[analysisType] || prompts.general;
    if (extraPrompt) prompt += `\n\nì¶”ê°€ ìš”ì²­: ${extraPrompt}`;

    await streamOllama([{ role: 'user', content: prompt }], res);
  } catch (err) {
    if (!res.headersSent) res.status(500).json({ error: err.message });
  } finally {
    try { fs.unlinkSync(req.file.path); } catch {}
  }
});

// â”€â”€ ì„œë²„ ìƒíƒœ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.get('/api/status', async (req, res) => {
  try {
    const data   = await (await fetch(`${OLLAMA_URL}/api/tags`)).json();
    const models = data.models?.map(m => m.name) || [];
    res.json({ status: 'ok', models, current: MODEL_NAME });
  } catch {
    res.status(500).json({ status: 'error', message: 'Ollamaì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' });
  }
});

app.listen(PORT, () => {
  console.log(`âœ… Bitdot AI: http://localhost:${PORT}`);
  console.log(`ğŸ¤– ëª¨ë¸: ${MODEL_NAME}`);
});
